"""
Model Conversion Script for TensorFlow.js

This script converts trained Keras/TensorFlow models to TensorFlow.js format
for deployment in the browser-based 2048 AI application.

IMPORTANT: Always run this script in a Python virtual environment!
Before running, ensure you have activated the venv:
    source venv/bin/activate  # On macOS/Linux
    pip install -r requirements.txt
"""

import os
import sys
import json
import argparse
import shutil
from pathlib import Path

import tensorflow as tf
import tensorflowjs as tfjs

def convert_model_to_tfjs(model_path, output_dir, quantize=True):
    """
    Convert a trained Keras model to TensorFlow.js format
    
    Args:
        model_path (str): Path to the trained Keras model (.h5 or SavedModel)
        output_dir (str): Output directory for TensorFlow.js model files
        quantize (bool): Whether to quantize the model for smaller size
    """
    try:
        print(f"Loading model from: {model_path}")
        
        # Load the trained Keras model
        model = tf.keras.models.load_model(model_path)
        print(f"Model loaded successfully. Architecture:")
        model.summary()
        
        # Create output directory if it doesn't exist
        os.makedirs(output_dir, exist_ok=True)
        
        print(f"Converting model to TensorFlow.js format...")
        print(f"Output directory: {output_dir}")
        
        # Convert model with optional quantization
        if quantize:
            print("Applying quantization for smaller model size...")
            tfjs.converters.save_keras_model(
                model,
                output_dir,
                quantization_bytes=1  # 8-bit quantization for smaller size
            )
        else:
            tfjs.converters.save_keras_model(model, output_dir)
        
        # Validate the conversion
        validate_conversion(output_dir, model)
        
        print("‚úÖ Model conversion completed successfully!")
        print(f"üìÅ Model files saved to: {output_dir}")
        
        # Display detailed model information
        model_info = get_model_info(output_dir)
        if model_info:
            print(f"üìã Model Format: {model_info['format']}")
            print(f"üîß Generated by: {model_info['generated_by']}")
            print(f"üîÑ Converted by: {model_info['converted_by']}")
            print("üìÅ Files created:")
            print("  - model.json (model architecture)")
            for weight_file in model_info['weight_files']:
                print(f"  - {weight_file['path']} ({weight_file['size_mb']} MB)")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Error during model conversion: {str(e)}")
        return False

def validate_conversion(output_dir, original_model):
    """
    Validate the converted TensorFlow.js model
    """
    try:
        print("Validating converted model...")
        
        # Check if model files exist
        model_json_path = os.path.join(output_dir, "model.json")
        if not os.path.exists(model_json_path):
            raise FileNotFoundError("model.json not found after conversion")
        
        # Load and verify model.json structure
        import json
        with open(model_json_path, 'r') as f:
            model_config = json.load(f)
        
        # Basic validation of model structure
        required_keys = ["format", "modelTopology", "weightsManifest"]
        for key in required_keys:
            if key not in model_config:
                raise ValueError(f"Missing required key in model.json: {key}")
        
        # Check weight files exist
        weight_files = []
        for manifest in model_config["weightsManifest"]:
            for path in manifest["paths"]:
                weight_path = os.path.join(output_dir, path)
                if not os.path.exists(weight_path):
                    raise FileNotFoundError(f"Weight file not found: {path}")
                weight_files.append(path)
        
        # Calculate model size
        total_size = 0
        for weight_file in weight_files:
            weight_path = os.path.join(output_dir, weight_file)
            total_size += os.path.getsize(weight_path)
        
        print(f"‚úÖ Model validation successful!")
        print(f"üìä Model files: {len(weight_files) + 1} files")
        print(f"üì¶ Total size: {total_size / (1024*1024):.2f} MB")
        
        # Compare with original model size
        original_params = original_model.count_params()
        print(f"üî¢ Original model parameters: {original_params:,}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Model validation failed: {str(e)}")
        return False

def get_model_info(output_dir):
    """
    Get information about the converted model
    """
    try:
        model_json_path = os.path.join(output_dir, "model.json")
        with open(model_json_path, 'r') as f:
            model_config = json.load(f)
        
        info = {
            "format": model_config.get("format", "unknown"),
            "generated_by": model_config.get("generatedBy", "unknown"),
            "converted_by": model_config.get("convertedBy", "unknown"),
            "weight_files": []
        }
        
        # Get weight file info
        for manifest in model_config.get("weightsManifest", []):
            for path in manifest["paths"]:
                weight_path = os.path.join(output_dir, path)
                if os.path.exists(weight_path):
                    size_mb = os.path.getsize(weight_path) / (1024*1024)
                    info["weight_files"].append({
                        "path": path,
                        "size_mb": round(size_mb, 2)
                    })
        
        return info
        
    except Exception as e:
        print(f"Warning: Could not get model info: {str(e)}")
        return None

def validate_model_files(output_dir):
    """
    Validate that all necessary TensorFlow.js model files exist
    """
    required_files = ["model.json"]
    
    for file in required_files:
        file_path = os.path.join(output_dir, file)
        if not os.path.exists(file_path):
            print(f"‚ùå Missing required file: {file}")
            return False
    
    # Check for weight files (*.bin)
    bin_files = [f for f in os.listdir(output_dir) if f.endswith('.bin')]
    if not bin_files:
        print("‚ùå No weight files (.bin) found")
        return False
    
    print("‚úÖ All required model files present")
    return True

def copy_to_frontend(output_dir, frontend_dir="../frontend/public/model"):
    """
    Copy the converted model to the frontend public directory
    """
    try:
        # Create frontend model directory if it doesn't exist
        frontend_model_dir = os.path.abspath(frontend_dir)
        os.makedirs(frontend_model_dir, exist_ok=True)
        
        # Clear existing model files in frontend directory
        for existing_file in os.listdir(frontend_model_dir):
            if existing_file.endswith(('.json', '.bin')):
                os.remove(os.path.join(frontend_model_dir, existing_file))
                print(f"üóëÔ∏è  Removed old model file: {existing_file}")
        
        # Copy all files from output_dir to frontend
        copied_files = []
        total_size = 0
        for file in os.listdir(output_dir):
            if os.path.isfile(os.path.join(output_dir, file)):
                src = os.path.join(output_dir, file)
                dst = os.path.join(frontend_model_dir, file)
                shutil.copy2(src, dst)
                file_size = os.path.getsize(src)
                total_size += file_size
                copied_files.append(file)
                print(f"üìã Copied {file} ({file_size / (1024*1024):.2f} MB)")
        
        print(f"‚úÖ Model files copied to frontend: {frontend_model_dir}")
        print(f"üì¶ Total size copied: {total_size / (1024*1024):.2f} MB")
        print(f"üìÅ Files available for web app: {', '.join(copied_files)}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Error copying to frontend: {str(e)}")
        return False

def main():
    parser = argparse.ArgumentParser(
        description="Convert trained 2048 CNN model to TensorFlow.js",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Basic conversion
  python convert_to_tfjs.py --model models/game2048_cnn.h5
  
  # Quantized conversion with frontend copy
  python convert_to_tfjs.py --model models/game2048_cnn.h5 --quantize --copy-to-frontend
  
  # Custom output directory
  python convert_to_tfjs.py --model models/game2048_cnn.h5 --output ./web_model
"""
    )
    
    parser.add_argument("--model", "-m", required=True, 
                       help="Path to trained Keras model (.h5 or SavedModel directory)")
    parser.add_argument("--output", "-o", default="./tfjs_model", 
                       help="Output directory for TensorFlow.js model (default: ./tfjs_model)")
    parser.add_argument("--quantize", action="store_true", 
                       help="Apply 8-bit quantization for smaller model size (~75%% reduction)")
    parser.add_argument("--copy-to-frontend", action="store_true", 
                       help="Copy converted model to frontend/public/model directory")
    parser.add_argument("--frontend-dir", default="../frontend/public/model",
                       help="Frontend model directory path (default: ../frontend/public/model)")
    parser.add_argument("--verbose", "-v", action="store_true",
                       help="Enable verbose output")
    
    args = parser.parse_args()
    
    print("üöÄ 2048 CNN Model Converter")
    print("=" * 50)
    print(f"üìÇ Input model: {args.model}")
    print(f"üìÅ Output directory: {args.output}")
    print(f"üóúÔ∏è  Quantization: {'Enabled' if args.quantize else 'Disabled'}")
    print(f"üìã Copy to frontend: {'Yes' if args.copy_to_frontend else 'No'}")
    if args.copy_to_frontend:
        print(f"üéØ Frontend directory: {args.frontend_dir}")
    print("-" * 50)
    
    # Check if model file exists
    if not os.path.exists(args.model):
        print(f"‚ùå Model file not found: {args.model}")
        print("üí° Make sure you have trained a model first using train_cnn.py")
        sys.exit(1)
    
    # Convert model
    success = convert_model_to_tfjs(args.model, args.output, args.quantize)
    
    if not success:
        print("‚ùå Conversion failed!")
        sys.exit(1)
    
    # Validate output
    if not validate_model_files(args.output):
        print("‚ùå Model validation failed!")
        sys.exit(1)
    
    # Copy to frontend if requested
    if args.copy_to_frontend:
        frontend_success = copy_to_frontend(args.output, args.frontend_dir)
        if not frontend_success:
            print("‚ö†Ô∏è  Model converted but frontend copy failed")
    
    print("\nüéâ Conversion process completed successfully!")
    print(f"üìÅ TensorFlow.js model available at: {os.path.abspath(args.output)}")
    
    if args.copy_to_frontend and frontend_success:
        print(f"üåê Model ready for web deployment in: {os.path.abspath(args.frontend_dir)}")
    
    print("\nüí° Next steps:")
    print("   1. Start your web application")
    print("   2. The AI model will be loaded automatically")
    print("   3. Test the AI performance in the game")

if __name__ == "__main__":
    main() 